{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMadIuBCFPOzw0JJ2Z6MPF3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msf1997/taiyo/blob/main/Assignment_Data_Engineer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9GXdWBFKgVHB"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class WorldBankTendersScraper:\n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "\n",
        "    def scrape(self):\n",
        "        response = requests.get(self.url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            tender_items = soup.find_all('div', class_='views-row')\n",
        "\n",
        "            data = []\n",
        "            for item in tender_items:\n",
        "                title_elem = item.find('div', class_='views-field-title')\n",
        "                title = title_elem.get_text().strip() if title_elem else \"N/A\"\n",
        "\n",
        "                description_elem = item.find('div', class_='views-field-field-pd-description')\n",
        "                description = description_elem.get_text().strip() if description_elem else \"N/A\"\n",
        "\n",
        "                project_elem = item.find('div', class_='views-field-field-pd-project')\n",
        "                project = project_elem.get_text().strip() if project_elem else \"N/A\"\n",
        "\n",
        "                country_elem = item.find('div', class_='views-field-field-pd-country')\n",
        "                country = country_elem.get_text().strip() if country_elem else \"N/A\"\n",
        "\n",
        "                data.append({\n",
        "                    'Title': title,\n",
        "                    'Description': description,\n",
        "                    'Project': project,\n",
        "                    'Country': country\n",
        "                })\n",
        "\n",
        "            return data\n",
        "        else:\n",
        "            print(f\"Failed to retrieve data from {self.url}\")\n",
        "            return []\n",
        "\n",
        "    def save_to_csv(self, data):\n",
        "        if data:\n",
        "            with open('world_bank_tenders.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "                fieldnames = ['Title', 'Description', 'Project', 'Country']\n",
        "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "                writer.writeheader()\n",
        "                for row in data:\n",
        "                    writer.writerow(row)\n",
        "            print(\"Data saved to world_bank_tenders.csv\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    url = 'https://ieg.worldbankgroup.org/data'\n",
        "    scraper = WorldBankTendersScraper(url)\n",
        "    scraped_data = scraper.scrape()\n",
        "    scraper.save_to_csv(scraped_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzElJHo8gvbR",
        "outputId": "db3c886a-9cb2-46c5-c326-ee45d6fae6de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to world_bank_tenders.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ChinaBiddingScraper:\n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "\n",
        "    def scrape(self):\n",
        "        response = requests.get(self.url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            tender_items = soup.find_all('div', class_='content-box')\n",
        "\n",
        "            data = []\n",
        "            for item in tender_items:\n",
        "                title_elem = item.find('h3', class_='news-hd')\n",
        "                title = title_elem.get_text().strip() if title_elem else \"N/A\"\n",
        "\n",
        "                date_elem = item.find('span', class_='time')\n",
        "                date = date_elem.get_text().strip() if date_elem else \"N/A\"\n",
        "\n",
        "                data.append({\n",
        "                    'Title': title,\n",
        "                    'Date': date\n",
        "                })\n",
        "\n",
        "            return data\n",
        "        else:\n",
        "            print(f\"Failed to retrieve data from {self.url}\")\n",
        "            return []\n",
        "\n",
        "    def save_to_csv(self, data):\n",
        "        if data:\n",
        "            with open('china_bidding_tenders.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "                fieldnames = ['Title', 'Date']\n",
        "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "                writer.writeheader()\n",
        "                for row in data:\n",
        "                    writer.writerow(row)\n",
        "            print(\"Data saved to china_bidding_tenders.csv\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    url = 'https://www.chinabidding.com/en'\n",
        "    scraper = ChinaBiddingScraper(url)\n",
        "    scraped_data = scraper.scrape()\n",
        "    scraper.save_to_csv(scraped_data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2Y4xrRehEfD",
        "outputId": "28dc3fb8-5af7-4ff8-d0d6-d457cf202c9f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve data from https://www.chinabidding.com/en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5jCpBPDCXddz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}